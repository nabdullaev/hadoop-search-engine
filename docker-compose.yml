services:
  cluster-master:
    image: firasj/spark-docker-cluster
    container_name: cluster-master
    ports:
      - "8088:8088"
      - "4040:4040"
      - "19888:19888"
      - "9000:9000"
      - "9870:9870"
      - "8032:8032"
    volumes:
      - "./app:/app"
      - "./configs/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml"
      - "./configs/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml"

    networks:
      - spark-cluster
    depends_on:
      - cluster-slave-1
      - cassandra-server
    hostname: cluster-master
    tty: true
    working_dir: /app
    # You can comment the entrypoint to run the script manually inside the container
    # environment:
    #   - SPARK_DRIVER_MEMORY=4g
    #   - SPARK_EXECUTOR_MEMORY=4g
    # entrypoint: 
    #   - bash
    #   - /app/app.sh
    
  cluster-slave-1:
    image: firasj/spark-docker-cluster
    container_name: cluster-slave-1
    networks:
      - spark-cluster
    hostname: cluster-slave-1
    tty: true
    volumes:
      - "./configs/yarn-site.xml:/usr/local/hadoop/etc/hadoop/yarn-site.xml"
      - "./configs/capacity-scheduler.xml:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml"
    ports:
    - "8042:8042"  
    - "37543:37543"  
  # cluster-slave-2:
  #   image: firasj/spark-docker-cluster
  #   container_name: cluster-slave-2
  #   networks:
  #     - spark-cluster
  #   depends_on:
  #     - cluster-slave-1
  #   hostname: cluster-slave-2
  #   tty: true
  cassandra-server:
    image: cassandra
    container_name: cassandra-server
    ports:
      - "7001:7000"
    networks:
      - spark-cluster
    

networks:
  spark-cluster:
    driver: bridge